{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout,Activation\n",
    "%matplotlib inline\n",
    "img_width, img_height = 224,224\n",
    "\n",
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))\n",
    "first_layer = model.layers[-1]\n",
    "# this is a placeholder tensor that will contain our generated images\n",
    "input_img = first_layer.input\n",
    "\n",
    "# build the rest of the network\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('softmax'))\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_79 (ZeroPadding2D)   (1, 3, 226, 226)    0           zeropadding2d_input_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Convolution2D)            (1, 64, 224, 224)   1792        zeropadding2d_79[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_80 (ZeroPadding2D)   (1, 64, 226, 226)   0           conv1_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Convolution2D)            (1, 64, 224, 224)   36928       zeropadding2d_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_31 (MaxPooling2D)     (1, 64, 112, 112)   0           conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_81 (ZeroPadding2D)   (1, 64, 114, 114)   0           maxpooling2d_31[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Convolution2D)            (1, 128, 112, 112)  73856       zeropadding2d_81[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_82 (ZeroPadding2D)   (1, 128, 114, 114)  0           conv2_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Convolution2D)            (1, 128, 112, 112)  147584      zeropadding2d_82[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_32 (MaxPooling2D)     (1, 128, 56, 56)    0           conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_83 (ZeroPadding2D)   (1, 128, 58, 58)    0           maxpooling2d_32[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Convolution2D)            (1, 256, 56, 56)    295168      zeropadding2d_83[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_84 (ZeroPadding2D)   (1, 256, 58, 58)    0           conv3_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Convolution2D)            (1, 256, 56, 56)    590080      zeropadding2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_85 (ZeroPadding2D)   (1, 256, 58, 58)    0           conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3 (Convolution2D)            (1, 256, 56, 56)    590080      zeropadding2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_33 (MaxPooling2D)     (1, 256, 28, 28)    0           conv3_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_86 (ZeroPadding2D)   (1, 256, 30, 30)    0           maxpooling2d_33[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Convolution2D)            (1, 512, 28, 28)    1180160     zeropadding2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_87 (ZeroPadding2D)   (1, 512, 30, 30)    0           conv4_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Convolution2D)            (1, 512, 28, 28)    2359808     zeropadding2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_88 (ZeroPadding2D)   (1, 512, 30, 30)    0           conv4_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3 (Convolution2D)            (1, 512, 28, 28)    2359808     zeropadding2d_88[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_34 (MaxPooling2D)     (1, 512, 14, 14)    0           conv4_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_89 (ZeroPadding2D)   (1, 512, 16, 16)    0           maxpooling2d_34[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Convolution2D)            (1, 512, 14, 14)    2359808     zeropadding2d_89[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_90 (ZeroPadding2D)   (1, 512, 16, 16)    0           conv5_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Convolution2D)            (1, 512, 14, 14)    2359808     zeropadding2d_90[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_91 (ZeroPadding2D)   (1, 512, 16, 16)    0           conv5_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3 (Convolution2D)            (1, 512, 14, 14)    2359808     zeropadding2d_91[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_35 (MaxPooling2D)     (1, 512, 7, 7)      0           conv5_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)                (1, 25088)          0           maxpooling2d_35[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                   (1, 4096)           102764544   flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)               (1, 4096)           0           dense_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                   (1, 4096)           16781312    dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)               (1, 4096)           0           dense_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                   (1, 1000)           4097000     dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)          (1, 1000)           0           dense_21[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 138357544\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Processing filter 0\n",
      "Current loss value: 5.54269981384\n",
      "Current loss value: 6.95668697357\n",
      "Current loss value: 7.96167421341\n",
      "Current loss value: 8.81514358521\n",
      "Current loss value: 9.60537528992\n",
      "Current loss value: 10.347281456\n",
      "Current loss value: 11.0452308655\n",
      "Current loss value: 11.7526531219\n",
      "Current loss value: 12.3907871246\n",
      "Current loss value: 13.0489864349\n",
      "Current loss value: 13.6905651093\n",
      "Current loss value: 14.3408288956\n",
      "Current loss value: 14.9309902191\n",
      "Current loss value: 15.5397415161\n",
      "Current loss value: 16.1099777222\n",
      "Current loss value: 16.7109546661\n",
      "Current loss value: 17.2888832092\n",
      "Current loss value: 17.8350276947\n",
      "Current loss value: 18.4204673767\n",
      "Current loss value: 18.9720973969\n",
      "Filter 0 processed in 9s\n",
      "Processing filter 1\n",
      "Current loss value: 29.7277126312\n",
      "Current loss value: 33.761100769\n",
      "Current loss value: 36.5732727051\n",
      "Current loss value: 38.9175033569\n",
      "Current loss value: 41.089931488\n",
      "Current loss value: 43.0596542358\n",
      "Current loss value: 44.9988021851\n",
      "Current loss value: 46.7794151306\n",
      "Current loss value: 48.5203514099\n",
      "Current loss value: 50.2044258118\n",
      "Current loss value: 51.775100708\n",
      "Current loss value: 53.3495788574\n",
      "Current loss value: 54.929069519\n",
      "Current loss value: 56.3819732666\n",
      "Current loss value: 57.8923454285\n",
      "Current loss value: 59.3611679077\n",
      "Current loss value: 60.8028068542\n",
      "Current loss value: 62.1012573242\n",
      "Current loss value: 63.5084342957\n",
      "Current loss value: 64.7784118652\n",
      "Filter 1 processed in 9s\n",
      "Processing filter 2\n",
      "Current loss value: 1.44765257835\n",
      "Current loss value: 2.96617245674\n",
      "Current loss value: 4.00473833084\n",
      "Current loss value: 4.89641046524\n",
      "Current loss value: 5.65116691589\n",
      "Current loss value: 6.3196849823\n",
      "Current loss value: 6.98312282562\n",
      "Current loss value: 7.62973690033\n",
      "Current loss value: 8.24983692169\n",
      "Current loss value: 9.01079177856\n",
      "Current loss value: 9.66019058228\n",
      "Current loss value: 10.300740242\n",
      "Current loss value: 10.8797044754\n",
      "Current loss value: 11.471124649\n",
      "Current loss value: 12.0396518707\n",
      "Current loss value: 12.6004858017\n",
      "Current loss value: 13.150929451\n",
      "Current loss value: 13.6757650375\n",
      "Current loss value: 14.1874799728\n",
      "Current loss value: 14.7265453339\n",
      "Filter 2 processed in 8s\n",
      "Processing filter 3\n",
      "Current loss value: 2.17463827133\n",
      "Current loss value: 3.11324334145\n",
      "Current loss value: 3.7681748867\n",
      "Current loss value: 4.34448003769\n",
      "Current loss value: 4.88962888718\n",
      "Current loss value: 5.40753650665\n",
      "Current loss value: 5.88275623322\n",
      "Current loss value: 6.32771110535\n",
      "Current loss value: 6.80889844894\n",
      "Current loss value: 7.28448915482\n",
      "Current loss value: 7.74680995941\n",
      "Current loss value: 8.16709804535\n",
      "Current loss value: 8.62372493744\n",
      "Current loss value: 9.01596164703\n",
      "Current loss value: 9.44720172882\n",
      "Current loss value: 9.82995128632\n",
      "Current loss value: 10.2248096466\n",
      "Current loss value: 10.6301784515\n",
      "Current loss value: 10.9835290909\n",
      "Current loss value: 11.3665647507\n",
      "Filter 3 processed in 8s\n",
      "Processing filter 4\n",
      "Current loss value: 0.0\n",
      "Filter 4 processed in 2s\n",
      "Processing filter 5\n",
      "Current loss value: 32.1541976929\n",
      "Current loss value: 36.3108711243\n",
      "Current loss value: 39.3279495239\n",
      "Current loss value: 41.7526664734\n",
      "Current loss value: 44.1241035461\n",
      "Current loss value: 46.3186454773\n",
      "Current loss value: 48.3963356018\n",
      "Current loss value: 50.45104599\n",
      "Current loss value: 52.4016418457\n",
      "Current loss value: 54.2963485718\n",
      "Current loss value: 56.1414451599\n",
      "Current loss value: 58.0590171814\n",
      "Current loss value: 59.857711792\n",
      "Current loss value: 61.6214256287\n",
      "Current loss value: 63.361492157\n",
      "Current loss value: 65.1568374634\n",
      "Current loss value: 66.8233184814\n",
      "Current loss value: 68.5625152588\n",
      "Current loss value: 70.2014465332\n",
      "Current loss value: 71.8890762329\n",
      "Filter 5 processed in 8s\n",
      "Processing filter 6\n",
      "Current loss value: 2.08314847946\n",
      "Current loss value: 3.94226837158\n",
      "Current loss value: 5.18851423264\n",
      "Current loss value: 6.30017995834\n",
      "Current loss value: 7.27598237991\n",
      "Current loss value: 8.20528793335\n",
      "Current loss value: 9.11439228058\n",
      "Current loss value: 10.0489530563\n",
      "Current loss value: 11.0291204453\n",
      "Current loss value: 11.8744068146\n",
      "Current loss value: 12.7333869934\n",
      "Current loss value: 13.5309333801\n",
      "Current loss value: 14.3470182419\n",
      "Current loss value: 15.1054649353\n",
      "Current loss value: 15.884223938\n",
      "Current loss value: 16.6248207092\n",
      "Current loss value: 17.3946418762\n",
      "Current loss value: 18.1213798523\n",
      "Current loss value: 18.8322257996\n",
      "Current loss value: 19.517829895\n",
      "Filter 6 processed in 9s\n",
      "Processing filter 7\n",
      "Current loss value: 9.95089530945\n",
      "Current loss value: 13.2854166031\n",
      "Current loss value: 15.5292596817\n",
      "Current loss value: 17.3640937805\n",
      "Current loss value: 19.1550178528\n",
      "Current loss value: 20.6658859253\n",
      "Current loss value: 22.2140541077\n",
      "Current loss value: 23.6173439026\n",
      "Current loss value: 25.0118045807\n",
      "Current loss value: 26.3201618195\n",
      "Current loss value: 27.5860271454\n",
      "Current loss value: 28.9430999756\n",
      "Current loss value: 30.1687755585\n",
      "Current loss value: 31.4597930908\n",
      "Current loss value: 32.6947174072\n",
      "Current loss value: 33.8692054749\n",
      "Current loss value: 35.0628051758\n",
      "Current loss value: 36.3175392151\n",
      "Current loss value: 37.4503517151\n",
      "Current loss value: 38.7040061951\n",
      "Filter 7 processed in 8s\n",
      "Processing filter 8\n",
      "Current loss value: 1.50851285458\n",
      "Current loss value: 2.25542283058\n",
      "Current loss value: 2.77605438232\n",
      "Current loss value: 3.25634121895\n",
      "Current loss value: 3.75315952301\n",
      "Current loss value: 4.16956043243\n",
      "Current loss value: 4.61612701416\n",
      "Current loss value: 5.01973867416\n",
      "Current loss value: 5.41634750366\n",
      "Current loss value: 5.79487133026\n",
      "Current loss value: 6.17027330399\n",
      "Current loss value: 6.55697822571\n",
      "Current loss value: 6.90451574326\n",
      "Current loss value: 7.26400947571\n",
      "Current loss value: 7.65843153\n",
      "Current loss value: 7.99536800385\n",
      "Current loss value: 8.33658313751\n",
      "Current loss value: 8.68912220001\n",
      "Current loss value: 9.03021621704\n",
      "Current loss value: 9.39602851868\n",
      "Filter 8 processed in 8s\n",
      "Processing filter 9\n",
      "Current loss value: 38.9022369385\n",
      "Current loss value: 43.2343711853\n",
      "Current loss value: 46.4180259705\n",
      "Current loss value: 49.1235466003\n",
      "Current loss value: 51.5567855835\n",
      "Current loss value: 53.901599884\n",
      "Current loss value: 56.2047462463\n",
      "Current loss value: 58.2951850891\n",
      "Current loss value: 60.3907966614\n",
      "Current loss value: 62.5422058105\n",
      "Current loss value: 64.611579895\n",
      "Current loss value: 66.6948013306\n",
      "Current loss value: 68.7413024902\n",
      "Current loss value: 70.6816101074\n",
      "Current loss value: 72.6879806519\n",
      "Current loss value: 74.6268920898\n",
      "Current loss value: 76.6497497559\n",
      "Current loss value: 78.5338287354\n",
      "Current loss value: 80.4512176514\n",
      "Current loss value: 82.3647613525\n",
      "Filter 9 processed in 9s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7716c34697b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkept_filters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n\u001b[0;32m    182\u001b[0m                          (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "\n",
    "This script can run on CPU in a few minutes (with the TensorFlow backend).\n",
    "\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "\n",
    "Before running this script, download the weights for the VGG16 model at:\n",
    "https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\n",
    "(source: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)\n",
    "and make sure the variable `weights_path` in this script matches the location of the file.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "\n",
    "# the name of the layer we want to visualize (see model definition below)\n",
    "layer_name = 'conv5_1'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, img_width, img_height)))\n",
    "first_layer = model.layers[-1]\n",
    "# this is a placeholder tensor that will contain our generated images\n",
    "input_img = first_layer.input\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in f.attrs['layer_names']:\n",
    "    \n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(0, 10):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    input_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n",
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('vgg16_weights.h5')\n",
    "a =  model.get_weights()\n",
    "print len(a[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "layer_name = 'conv5_1'\n",
    "filter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n",
    "\n",
    "# build a loss function that maximizes the activation\n",
    "# of the nth filter of the layer considered\n",
    "layer_output = layer_dict[layer_name].output\n",
    "loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_img], [loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# we start from a gray image with some noise\n",
    "input_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n",
    "# run gradient ascent for 20 steps\n",
    "for i in range(20):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "img = input_img_data[0]\n",
    "img = deprocess_image(img)\n",
    "imsave('%s_filter_%d.png' % (layer_name, filter_index), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaxPooling2D' object has no attribute 'get_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8256f9671e94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaxPooling2D' object has no attribute 'get_output'"
     ]
    }
   ],
   "source": [
    "input_img_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
